{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {},
        "id": "-xoTtYYyo3KO"
      },
      "outputs": [],
      "source": [
        "from utils.imports import *\n",
        "from utils.data_loader import download_data, load_data\n",
        "from utils.models import PretrainedModel, AlexNetVanilla\n",
        "from utils.utils import preprocess_images, get_current_time\n",
        "from utils.config import batch_size, num_epochs, model_str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Initialize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "fnames = [\"../kay_labels.npy\", \"../kay_labels_val.npy\", \"../kay_images.npz\"]\n",
        "urls = [\"https://osf.io/r638s/download\",\n",
        "        \"https://osf.io/yqb3e/download\",\n",
        "        \"https://osf.io/ymnjv/download\"]\n",
        "\n",
        "if download_data(fnames, urls):\n",
        "    init_training_inputs, init_test_inputs, training_outputs, test_outputs, roi, roi_names, labels, val_labels = load_data('../kay_images.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create validation set of 10% of training set\n",
        "#val_inputs = init_training_inputs[-100:]\n",
        "#val_outputs = training_outputs[-100:]\n",
        "#init_training_inputs = init_training_inputs[:-100]\n",
        "#training_outputs = training_outputs[:-100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Outlier detection and handling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In a normal distribution, 99.7% of the data is within +/- 3 standard deviations of the mean. We can use this to identify outliers in the data. \n",
        "\n",
        "Next is deciding on how to handle outliers, e.g.:\n",
        "\n",
        "- Exclude Outliers: Exclude any voxels that are outliers in any of the images. This is a stringent approach but ensures that your model is not influenced by these extreme values.\n",
        "- Exclude Outliers on a Per-Image Basis: Instead of excluding a voxel across all images, you could exclude it only for those specific images where it's an outlier. This retains more data but can complicate the modeling process.\n",
        "- Winsorize Outliers: Instead of excluding outliers, you can cap them at the nearest non-outlier value (e.g., set all values above 3 to 3 and all below -3 to -3). This method reduces the impact of extreme values without losing data.\n",
        "- Replace with mean: We can replace outliers with the mean of the data. This is a simple approach, but it can introduce bias into the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(Train) Responses shape:  (1750, 8428)\n",
            "(Train) Total number of voxels:  14749000\n",
            "(Train) Number of voxels outside [-3, 3] Z-score:  51365\n",
            "(Train) Ratio of voxels outside [-3, 3] Z-score compared to total:  0.348260899044003 %\n",
            "(Train) Number of distinct responses with outlier voxel:  1748\n",
            "(Train) Number of distinct outlier voxels:  8402\n",
            "(Train) Number of times each outlier voxel is an outlier:  [6 4 8 ... 2 7 6]\n",
            "(Train) Max number of times an outlier voxel is an outlier:  22\n",
            "(Train) Min number of times an outlier voxel is an outlier:  1\n"
          ]
        }
      ],
      "source": [
        "# TRAINING DATA\n",
        "# Train data shape\n",
        "print(\"(Train) Responses shape: \", training_outputs.shape)\n",
        "\n",
        "# Total number of voxels\n",
        "print(\"(Train) Total number of voxels: \", training_outputs.size)\n",
        "\n",
        "# For all images, count how many voxels are outside the range [-3, 3] Z-score.\n",
        "print(\"(Train) Number of voxels outside [-3, 3] Z-score: \",\n",
        "        np.sum(np.abs(training_outputs) > 3))\n",
        "\n",
        "# Ratio of voxels outside [-3, 3] Z-score\n",
        "print(\"(Train) Ratio of voxels outside [-3, 3] Z-score compared to total: \",\n",
        "        np.sum(np.abs(training_outputs) > 3) / training_outputs.size * 100, \"%\")\n",
        "\n",
        "# How many distinct responses have an outlier voxel?\n",
        "print(\"(Train) Number of distinct responses with outlier voxel: \",\n",
        "        np.unique(np.where(np.abs(training_outputs) > 3)[0]).size)\n",
        "\n",
        "# Count distinct voxels that are outliers and how many times that specific voxel is an outlier\n",
        "outlier_voxels, outlier_counts = np.unique(np.where(np.abs(training_outputs) > 3)[1], return_counts=True)\n",
        "print(\"(Train) Number of distinct outlier voxels: \", outlier_voxels.size)\n",
        "print(\"(Train) Number of times each outlier voxel is an outlier: \", outlier_counts)\n",
        "\n",
        "# Max and min in outlier_counts\n",
        "print(\"(Train) Max number of times an outlier voxel is an outlier: \", np.max(outlier_counts))\n",
        "print(\"(Train) Min number of times an outlier voxel is an outlier: \", np.min(outlier_counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(Test) Responses shape:  (120, 8428)\n",
            "(Test) Total number of voxels:  1011360\n",
            "(Test) Number of voxels outside [-3, 3] Z-score:  37\n",
            "(Test) Ratio of voxels outside [-3, 3] Z-score compared to total:  0.00365844012023414 %\n",
            "(Test) Number of distinct responses with outlier voxel:  21\n",
            "(Test) Number of distinct outlier voxels:  27\n",
            "(Test) Number of times each outlier voxel is an outlier:  [ 1  1  1  1  1  1 10  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
            "  2  1  1]\n"
          ]
        }
      ],
      "source": [
        "# TEST DATA\n",
        "# Test data shape\n",
        "print(\"(Test) Responses shape: \", test_outputs.shape)\n",
        "\n",
        "# Total number of voxels\n",
        "print(\"(Test) Total number of voxels: \", test_outputs.size)\n",
        "\n",
        "# For all images, count how many voxels are outside the range [-3, 3] Z-score.\n",
        "print(\"(Test) Number of voxels outside [-3, 3] Z-score: \",\n",
        "        np.sum(np.abs(test_outputs) > 3))\n",
        "\n",
        "# Ratio of voxels outside [-3, 3] Z-score\n",
        "print(\"(Test) Ratio of voxels outside [-3, 3] Z-score compared to total: \",\n",
        "        np.sum(np.abs(test_outputs) > 3) / test_outputs.size * 100, \"%\")\n",
        "\n",
        "# How many distinct responses have an outlier voxel?\n",
        "print(\"(Test) Number of distinct responses with outlier voxel: \",\n",
        "        np.unique(np.where(np.abs(test_outputs) > 3)[0]).size)\n",
        "\n",
        "# Count distinct voxels that are outliers and how many times that specific voxel is an outlier\n",
        "outlier_voxels, outlier_counts = np.unique(np.where(np.abs(test_outputs) > 3)[1], return_counts=True)\n",
        "print(\"(Test) Number of distinct outlier voxels: \", outlier_voxels.size)\n",
        "print(\"(Test) Number of times each outlier voxel is an outlier: \", outlier_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Transformations and normalization to fit PyTorch models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocess the images\n",
        "training_inputs = preprocess_images(init_training_inputs)\n",
        "test_inputs = preprocess_images(init_test_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training input shape: (1750, 3, 224, 224)\n",
            "Test input shape: (120, 3, 224, 224)\n"
          ]
        }
      ],
      "source": [
        "# Print shapes of the preprocessed data\n",
        "print(\"Training input shape:\", training_inputs.shape)\n",
        "print(\"Test input shape:\", test_inputs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reducing output size to number of ROI's instead of voxels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1750, 7)\n",
            "Example values: [-0.23860244 -0.12070409 -0.10817796 -0.14121429 -0.33175569 -0.19762734\n",
            " -0.11004769]\n"
          ]
        }
      ],
      "source": [
        "# Preprocess outputs to be the mean of each ROI instead of each voxel.\n",
        "# This reduces the outputs to be predicted from 8428 to 7, hopefully not losing too much detail in the data in the process.\n",
        "def reduce_outputs_to_ROIs(outputs):\n",
        "    roi_count_dict = dict(zip(roi_names, np.bincount(roi)))\n",
        "    roi_order = np.argsort(roi)\n",
        "    sorted_responses = training_outputs[:, roi_order]\n",
        "\n",
        "    training_outputs_reduced_to_ROIs = np.zeros((len(outputs), 7))\n",
        "    for sample in range(len(training_outputs_reduced_to_ROIs)):\n",
        "        oldValue = 0\n",
        "        count = 0\n",
        "        for key, value in roi_count_dict.items():\n",
        "            if value > 0:\n",
        "                response_values = sorted_responses[:, oldValue:oldValue+value]\n",
        "                summed_roi = np.mean(response_values[sample])\n",
        "                training_outputs_reduced_to_ROIs[sample][count] = summed_roi\n",
        "                count += 1\n",
        "            oldValue = value\n",
        "    return training_outputs_reduced_to_ROIs\n",
        "\n",
        "print(reduce_outputs_to_ROIs(training_outputs).shape)\n",
        "print('Example values:', reduce_outputs_to_ROIs(training_outputs)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Encoder model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.utils import calculate_pca\n",
        "\n",
        "\n",
        "class Encoder():\n",
        "    def __init__(self, input, output, model_str):\n",
        "        self.input = input\n",
        "        self.output = output\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        self.best_loss = float('inf')\n",
        "        self.model_str = model_str\n",
        "\n",
        "    def extract_features(self, dataloader, model):\n",
        "        features = []\n",
        "        labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels_batch in dataloader:\n",
        "                # Extract features\n",
        "                feature_output = PretrainedModel.forward_features_only(model,inputs)\n",
        "                features.append(feature_output)\n",
        "\n",
        "                # Collect labels\n",
        "                labels.append(labels_batch)\n",
        "\n",
        "        # Concatenate all features and labels\n",
        "        features = torch.cat(features)\n",
        "        labels = torch.cat(labels)\n",
        "        return features, labels\n",
        "\n",
        "    def setup_model(self, batch_size):\n",
        "        x_train, x_val, y_train, y_val = train_test_split(self.input, self.output, test_size=0.1)\n",
        "        x_train_tensor, y_train_tensor = torch.from_numpy(x_train).float(), torch.from_numpy(y_train).float()\n",
        "        x_val_tensor, y_val_tensor = torch.from_numpy(x_val).float(), torch.from_numpy(y_val).float()\n",
        "\n",
        "        train_data_tensor = torch.utils.data.TensorDataset(x_train_tensor, y_train_tensor)\n",
        "        val_data_tensor = torch.utils.data.TensorDataset(x_val_tensor, y_val_tensor)\n",
        "        train_dataloader = torch.utils.data.DataLoader(train_data_tensor, batch_size, shuffle=True)\n",
        "        val_dataloader = torch.utils.data.DataLoader(val_data_tensor, batch_size, shuffle=False)\n",
        "\n",
        "        encoder_model = PretrainedModel(model_str=self.model_str)\n",
        "        criterion = nn.MSELoss()\n",
        "\n",
        "        # Freeze all layers except the classifier\n",
        "        for name, param in encoder_model.named_parameters():\n",
        "            if \"classifier\" in name:\n",
        "                param.requires_grad = True\n",
        "            else:\n",
        "                param.requires_grad = False\n",
        "        \n",
        "        optimizer = optim.Adam(encoder_model.parameters(), lr=0.0001)\n",
        "\n",
        "\n",
        "        # Extract features\n",
        "        train_features, train_labels = self.extract_features(train_dataloader,encoder_model)\n",
        "        val_features, val_labels = self.extract_features(val_dataloader,encoder_model)\n",
        "\n",
        "        # Create new TensorDatasets with extracted features\n",
        "        train_data_tensor = torch.utils.data.TensorDataset(train_features, train_labels)\n",
        "        val_data_tensor = torch.utils.data.TensorDataset(val_features, val_labels)\n",
        "\n",
        "        # Create new Dataloaders with these datasets\n",
        "        train_dataloader = torch.utils.data.DataLoader(train_data_tensor, batch_size, shuffle=True)\n",
        "        val_dataloader = torch.utils.data.DataLoader(val_data_tensor, batch_size, shuffle=False)\n",
        "\n",
        "        return encoder_model, criterion, optimizer, train_dataloader, val_dataloader\n",
        "\n",
        "    def train_one_epoch(self, train_dataloader, optimizer, criterion, encoder):\n",
        "        encoder.train()\n",
        "        train_running_loss = 0.0\n",
        "\n",
        "        for data in train_dataloader:\n",
        "            inputs, targets = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = encoder(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_running_loss += loss.item()\n",
        "\n",
        "        average_train_loss = train_running_loss / len(train_dataloader)\n",
        "        return average_train_loss\n",
        "\n",
        "    def validate(self, val_dataloader, criterion, encoder):\n",
        "        encoder.eval()\n",
        "        val_running_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data in val_dataloader:\n",
        "                inputs, targets = data\n",
        "                outputs = encoder(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "                val_running_loss += loss.item()\n",
        "\n",
        "        average_val_loss = val_running_loss / len(val_dataloader)\n",
        "        return average_val_loss\n",
        "\n",
        "    def train(self, batch_size, num_epochs):\n",
        "        timestamp = get_current_time()\n",
        "        encoder_model, criterion, optimizer, train_dataloader, val_dataloader = self.setup_model(batch_size)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            if epoch == 0:\n",
        "                print(f'Training {self.model_str} for {num_epochs} epochs...')\n",
        "                print(encoder_model)\n",
        "            train_loss = self.train_one_epoch(train_dataloader, optimizer, criterion, encoder_model)\n",
        "            val_loss = self.validate(val_dataloader, criterion, encoder_model)\n",
        "            self.losses.append(train_loss)\n",
        "            self.val_losses.append(val_loss)\n",
        "\n",
        "            if val_loss < self.best_loss:\n",
        "                self.best_loss = val_loss\n",
        "                best_model = encoder_model.state_dict()\n",
        "                torch.save(best_model, f'../trained_models/{self.model_str}_model_{timestamp}.pth')\n",
        "\n",
        "            print(f'Epoch {epoch+1}/{num_epochs} - Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
        "\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                # Plot loss curve\n",
        "                plt.figure(figsize=(10, 5))\n",
        "                plt.title(f'{model_str} - Encoder Loss')\n",
        "                plt.plot(self.losses, label=\"Encoder Loss\")\n",
        "                plt.plot(self.val_losses, label=\"Encoder Validation Loss\")\n",
        "                plt.xlabel(\"Iterations\")\n",
        "                plt.ylabel(\"Epoch\")\n",
        "                plt.legend()\n",
        "\n",
        "                if epoch == num_epochs - 1:\n",
        "                    save_dir = '../loss_plots/'\n",
        "\n",
        "                    # Check if the directory exists\n",
        "                    if not os.path.exists(save_dir):\n",
        "                        os.makedirs(save_dir)  # Create the directory if it does not exist\n",
        "\n",
        "                    # Save plot of loss curve. Format: loss_{num_epochs}_{timestamp].png\n",
        "                    plt.savefig(os.path.join(save_dir, f'{model_str}_loss_{timestamp}.png'))\n",
        "\n",
        "                plt.show()\n",
        "\n",
        "        return encoder_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Original input data shape:', training_inputs.shape)\n",
        "print('Original outputs data shape:', training_outputs.shape)\n",
        "print('')\n",
        "print('Running with parameters:')\n",
        "print('     Batch size:', batch_size)\n",
        "print('     Number of epochs:', num_epochs)\n",
        "print('     Model:', model_str)\n",
        "print('')\n",
        "\n",
        "pca_output, pca = calculate_pca(training_outputs)\n",
        "# Setup model and train it\n",
        "encoder = Encoder(training_inputs, pca_output, model_str)\n",
        "trained_model = encoder.train(batch_size=batch_size, num_epochs=num_epochs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "load_kay_images",
      "provenance": [],
      "toc_visible": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
